# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы, я придумал использовать такую метрику: время выполнения метода work в секундах для одного и того же набора входных данных.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за время менее 5 секунд, выделенное на запуск и выполнение специально написанных тестов (на выборке 10000 записей), которые в свою очередь проверяют соответствие выбранной метрики и бюджета.

Вот как я построил `feedback_loop`:

Фреймворк оптимизации подразумевает наличие последовательности Profile – Modify – Test – Benchmark – Commit/Revert для проверки гипотез по вариантам улучшений. Т.к. мы не можем запустить нашу программу на исходном большом целевом файле с данными (слишком долгое время обработки), для создания быстрого feedback loop потребовался еще предварительный шаг, где предоставленные данные разбиваются на меньшие объемы, и уже на основе них строятся тесты для фиксирования текущей производительности как отправной точки. Кроме этого было необходимо расширить метод work для передачи опционального параметра с названием файла. По умолчанию метод бы запускался с прежним существующим файлом data.txt, а для новых тестов можно было бы передавать названия файлов с бОльшими выборками. Самая первая итерация представляла из себя написание тестов производительности (время выполнения программы, число итераций в единицу времени). В данном случае это можно отнести к шагу Profile & Test & Benchmark. Полученные при первом запуске значения бенчмарка мы можем записать в цели теста для исключения регрессий на последующих итерациях. Теперь, получив отправное время выполнения программы на разных небольших наборах данных, мы можем оценить асимптотику, дописав еще один тест для ее оценки. Она оказалась линейной при запуске программы для 100 первых строк, затем 1000 и затем 10000 строк.
С этого момента наш feedback loop создан, и мы можем переходить к профилированию и изменению кода, после чего запускать уже написанные тесты для сравнения результатов с отправным шагом (или шагом предыдущей итерации).
Код без изменений показал следующую производительность для Ruby 2.7.7 на небольших размерах данных: для 100 первых строк из data_large.txt время выполнения составило около 0.7мс, число итераций за 1 секунду не менее 1.54k.

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался ruby-prof

Вот какие проблемы удалось найти и решить

### Ваша находка №1
- какой отчёт показал главную точку роста:
  * ruby-prof в режиме Flat с профилем на 10.000 строк указал на большее время проведенное внутри метода Array#select: 86.59% времени при 1536 вызовах. Это и есть наша первая точка роста. На втором месте был Array#all? с 4,36% времени и 10.000 вызовами. На третьем месте был Array#each с 4,3% времени и 10 вызовами
- как вы решили её оптимизировать:
  * число вызовов говорит нам о том, что мы много раз обходим один и тот же массив сессий, чтобы найти в нем те или иные данные, соответствующие пользователям. Мы можем переписать этот цикл так, чтобы мы не начинали обход всех сессий заново по каждому пользователю, а прошли весь массив один раз, и уже внутри этого обхода сопостовляли текущую сессию с тем или иным пользователем, обновляя статистику для него
- как изменилась метрика:
  * время выполнения для 10.000 строк сократилось с 0.72 сек до 0.1 сек
- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?
  * да, точка роста перестала отображаться среди первых 6 результатов. Теперь на первое место вывел Array#each с 33.07% и 11 вызовами. На втором месте Array#all? с 31.95% и 10.000 вызовами

### Ваша находка №2
- какой отчёт показал главную точку роста:
  * из-за наличия нескольких вызовов метода each необходимо было воспользоваться другим режимом вывода информации профилировщиком, например в виде HTML таблицы вызовов и зависимостей методов (ruby-prof GraphHtmlPrinter). Больше всего вызовов each происходило внутри метода collect_stats_from_users. Это станет нашей второй точкой роста.
- как вы решили её оптимизировать
  * как мы видим, число вызовов each внутри этого метода корреллирует напрямую с множественными вызовами самой collect_stats_from_users. Для сбора разной статистики по разным категориям мы каждый раз снова вызываем метод и снова обходим всех имеющихся пользователей, чтобы найти соответствия. Придется провести рефакторинг, ведь всю информацию можно получить из данных о сессиях для каждого пользователя за один раз. Стоит объединить все отдельные вызываемые блоки в один большой, который мы и передадим в collect_stats_from_users для выполнения над каждым пользователем
- как изменилась метрика
  * время выполнения для 10.000 строк осталось прежним
- как изменился отчёт профилировщика - исправленная проблема перестала быть главной точкой роста?
  * да, вызовы each сместились на второе место, вперед вышел метод all? на 82 строке

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с *того, что у вас было в начале, до того, что получилось в конце* и уложиться в заданный бюджет.

*Какими ещё результами можете поделиться*

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы *о performance-тестах, которые вы написали*

